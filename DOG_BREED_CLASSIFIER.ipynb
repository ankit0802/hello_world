{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit0802/hello_world/blob/master/DOG_BREED_CLASSIFIER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAmM78l-wv9L"
      },
      "source": [
        "# Loading key-value pair dictionaries of labels and file paths can be done as follow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSINSyPz8cAV",
        "outputId": "ac7c04a2-2c80-4487-c6dd-86c186e3811d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qt2T4BfR-dy8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files \n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# defining the funtion to load train  ,tesy, and validate data set #\n",
        "\n",
        "def load_dataset(path):\n",
        "  data = load_files(path)\n",
        "  dog_files = np.array(data['filenames'])\n",
        "  dog_targets = np_utils.to_categorical(np.array(data['target']),133)\n",
        "  return dog_files ,dog_targets\n",
        "#### load train ,test ,and validation datasets ####\n",
        "train_files, train_targets = load_dataset('/content/gdrive/MyDrive/dogImages/dogImages/train')\n",
        "valid_files, valid_targets = load_dataset('/content/gdrive/MyDrive/dogImages/dogImages/valid')\n",
        "test_files, test_targets = load_dataset('/content/gdrive/MyDrive/dogImages/dogImages/test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVbI26Nwt1DO"
      },
      "source": [
        "#  The following codes resize the input to 224*224 pixels image and load it to memory as numpy series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y5os-v19uFVl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tqdm import tqdm\n",
        "from keras.utils import load_img, img_to_array\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "  #load RGB image as PIL.Image.Image type\n",
        "\n",
        "  img=image.load_img(img_path,target_size=(224,224))\n",
        "\n",
        "  #convert PIL.Image.Image type to 3D tensor with shape (224,224,3)\n",
        "\n",
        "  x= image.img_to_array(img)\n",
        "  #convert 3D tensor to 4D tensor with shape (1,224,224,3) and return 4D tensor\n",
        "\n",
        "  return np.expand_dims(x,axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "  list_of_tensors=[path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "  \n",
        "  return np.vstack(list_of_tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr18LULRguhE"
      },
      "source": [
        "# Pre-process data\n",
        "We need to normalize our data to eliminate units of measurement. Normalization can help our model better compare data of different scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMSVlTcDhD_G",
        "outputId": "e3fdc544-dd13-4a90-fd64-9eb03f4a472a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6689/6689 [00:56<00:00, 119.29it/s]\n",
            "100%|██████████| 835/835 [00:07<00:00, 116.07it/s]\n",
            "100%|██████████| 836/836 [00:06<00:00, 123.23it/s]\n"
          ]
        }
      ],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES=True\n",
        "\n",
        "#Preprocess the data for Keras\n",
        "\n",
        "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
        "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
        "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a model using transfer learning"
      ],
      "metadata": {
        "id": "C2cMdvH1ZlcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz'\n",
        "r = requests.get(url)\n",
        "with open('bottleneck_features/DogResnet50Data.npz', 'wb') as f:\n",
        "    f.write(r.content)\n",
        "bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')\n",
        "train_Resnet50 = bottleneck_features['train']\n",
        "valid_Resnet50 = bottleneck_features['valid']\n",
        "test_Resnet50 = bottleneck_features['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "H3nwGLiwZqgG",
        "outputId": "3f6234c7-3b2e-4768-af44-de21af95b5ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8fd222dacb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck_features/DogResnet50Data.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbottleneck_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck_features/DogResnet50Data.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bottleneck_features/DogResnet50Data.npz'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFyINAvSRsDI4NFHrpOiB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}